{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "54cc96a45fc3b47501632754ced5d8b28ece8c410f9e09f1bbcf5ca92f79b635"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Test inference piple\n",
    "\n",
    "Test running images through Megadetector API to obtain object bounding boxes, then on to the MIRA API for species classification.\n",
    "\n",
    "Adapted from http://dolphinvm.westus2.cloudapp.azure.com/ai4e/notebooks/cameratrap-sync-api-demo.html#Camera-trap-detection-API-demo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Setup\n",
    "#### 1) Make sure virtual env is running and requirements.txt are installed (see README.md)\n",
    "#### 2) Load Megadetector API key from .env file\n",
    "You'll need to have a .env file somewhere in the project directory with the API key set to \"MEGADETECTOR_API_KEY\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "MEGADETECTOR_API_KEY = os.getenv('MEGADETECTOR_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image,ImageDraw\n",
    "from azure.storage.blob import ContainerClient,BlobClient\n",
    "\n",
    "%autosave 0\n",
    "\n",
    "# Microsoft demo images:\n",
    "demo_image_account_name = 'cameratrapblobs'\n",
    "demo_image_container_name = 'cameratrapblobcontainer'\n",
    "demo_image_account_url = 'https://' + demo_image_account_name + '.blob.core.windows.net/'\n",
    "demo_image_blob_root = demo_image_account_url + demo_image_container_name\n",
    "demo_image_container_client = ContainerClient(\n",
    "    account_url=demo_image_account_url, \n",
    "    container_name=demo_image_container_name,\n",
    "    credential=None)\n",
    "\n",
    "# TNC test images (hosted):\n",
    "test_images_remote = []\n",
    "test_images_root = 'https://animl-test-images.s3-us-west-1.amazonaws.com/'\n",
    "remote_image_files = [\n",
    "    'sample-img-skunk-large.jpg',\n",
    "    'p_001205.jpg',\n",
    "    'p_001218.jpg',\n",
    "]\n",
    "for fil in remote_image_files:\n",
    "    test_images_remote.append(test_images_root + fil)\n",
    "\n",
    "# TNC test images (local):\n",
    "test_images_local = []\n",
    "test_images_dir = os.path.abspath(os.path.join(os.path.abspath(''), '..', 'input'))\n",
    "local_image_files = [\n",
    "    'sample-img.jpg',\n",
    "    'sample-img-skunk-large.jpg',\n",
    "    'sample-img-rodent.jpg',\n",
    "    'sample-img-fox.jpg',\n",
    "    'sample-img-fox-2.jpg',\n",
    "]\n",
    "for fil in local_image_files:\n",
    "    test_images_local.append(os.path.join(test_images_dir, fil))\n",
    "\n",
    "# Megadetector API config\n",
    "md_api_subscription_key = MEGADETECTOR_API_KEY\n",
    "md_api_base_url = 'https://aiforearth.azure-api.net/api/v1/camera-trap/sync/'\n",
    "md_api_detection_url = md_api_base_url + '/detect'\n",
    "md_api_version_url = md_api_base_url + '/detector_model_version'\n",
    "min_confidence_to_retrieve = 0.5\n",
    "min_confidence_to_display = 0.8\n",
    "\n",
    "# MIRA API config\n",
    "mira_api_url = 'https://2xuiw1fidh.execute-api.us-west-1.amazonaws.com/dev/classify'\n"
   ]
  },
  {
   "source": [
    "### Megadetector API health/version checkÂ¶"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = { 'Ocp-Apim-Subscription-Key': md_api_subscription_key }\n",
    "version_info = requests.get(md_api_version_url,headers=headers)\n",
    "version_info.text"
   ]
  },
  {
   "source": [
    "### Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def get_msft_demo_images():\n",
    "    \n",
    "    images_data = []\n",
    "    generator = demo_image_container_client.list_blobs()\n",
    "\n",
    "    for blob in generator:                  \n",
    "        blob_client = BlobClient(demo_image_account_url,demo_image_container_name,blob.name)\n",
    "        download_stream = blob_client.download_blob()\n",
    "        images_data.append({'name' : blob.name, 'data': download_stream.readall()})\n",
    "        # print('Read {} bytes'.format(len(images_data[-1]['data'])))\n",
    "    \n",
    "    return images_data   \n",
    "\n",
    "\n",
    "def get_tnc_images_remote():\n",
    "\n",
    "    images_data = []\n",
    "    for url in test_images_remote:\n",
    "        with urllib.request.urlopen(url) as img:\n",
    "            images_data.append({'name': url, 'data': BytesIO(img.read()).read()})\n",
    "            \n",
    "    return images_data\n",
    "\n",
    "\n",
    "def get_tnc_images_local():\n",
    "\n",
    "    images_data = []\n",
    "    for fil in test_images_local:\n",
    "        with open(fil, \"rb\") as img:\n",
    "            images_data.append({'name': fil, 'data': img.read()})\n",
    "            \n",
    "    return images_data\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,ymin,xmin,ymax,xmax):\n",
    "\n",
    "    color = 'red'\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "               (right, top), (left, top)], width=4, fill=color)\n",
    "    \n",
    "\n",
    "    \n",
    "def draw_raw_images():  \n",
    "    \n",
    "    fig = plt.figure(figsize=(20,35))\n",
    "\n",
    "    num_images = len(images)\n",
    "    \n",
    "    columns = 2\n",
    "\n",
    "    rows = (num_images // 2) + (num_images % 2)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        image = Image.open(BytesIO(images[i]['data']))        \n",
    "        axis = plt.subplot(rows,columns, i + 1)     \n",
    "        axis.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.axis('tight')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def response_to_json(r):\n",
    "    \n",
    "    from requests_toolbelt.multipart import decoder\n",
    "    res = decoder.MultipartDecoder.from_response(r)\n",
    "    results = {}\n",
    "    images = {}\n",
    "\n",
    "    for part in res.parts:\n",
    "        \n",
    "        # 'part' is a BodyPart object with b'Content-Type', and b'Content-Disposition';\n",
    "        # the latter includes 'name' and 'filename' info\n",
    "\n",
    "        headers = {}\n",
    "        for k, v in part.headers.items():\n",
    "            headers[k.decode(part.encoding)] = v.decode(part.encoding)\n",
    "\n",
    "        if headers.get('Content-Type', None) == 'image/jpeg':\n",
    "            c = headers.get('Content-Disposition')\n",
    "            image_name = c.split('name=\"')[1].split('\"')[0]\n",
    "            image = Image.open(io.BytesIO(part.content))\n",
    "            images[image_name] = image\n",
    "        elif headers.get('Content-Type', None) == 'application/json':\n",
    "            content_disposition = headers.get('Content-Disposition', '')\n",
    "            if 'detection_result' in content_disposition:\n",
    "                results['detection_result'] = json.loads(part.content.decode())\n",
    "            elif 'classification_result' in content_disposition:\n",
    "                results['classification_result'] = json.loads(part.content.decode())\n",
    "                \n",
    "    # ...for each part\n",
    "    \n",
    "    return results,images\n",
    "\n",
    "\n",
    "def call_megadetector(image_info):\n",
    "    \n",
    "    image_bytes = image_info['data']\n",
    "    image_name = image_info['name']\n",
    "    \n",
    "    assert isinstance(image_bytes,bytes)\n",
    "    file = BytesIO(image_bytes)\n",
    "    files = {}\n",
    "    files[image_name] = (image_name, file, 'application/octet-stream')\n",
    "    \n",
    "    headers = { 'Ocp-Apim-Subscription-Key': md_api_subscription_key }\n",
    "    params = {\n",
    "        'confidence': min_confidence_to_retrieve,\n",
    "        'render': False\n",
    "    }\n",
    "    \n",
    "    r = requests.post(md_api_detection_url, params=params, headers=headers, files=files)\n",
    "    \n",
    "    return r\n",
    "\n",
    "\n",
    "def call_mira(image_info):\n",
    "\n",
    "    image_bytes = image_info.get('data')\n",
    "    image_name = image_info.get('name')\n",
    "    image_bbox = image_info.get('bbox')\n",
    "\n",
    "    fields = {}\n",
    "    fields['image'] = (image_name, image_bytes, 'image/jpeg')\n",
    "    fields['bbox'] = json.dumps(image_bbox)\n",
    "    \n",
    "    multipart_data = MultipartEncoder(fields = fields)\n",
    "    r = requests.post(mira_api_url,\n",
    "                      data = multipart_data,\n",
    "                      headers = {'Content-Type': multipart_data.content_type})\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "source": [
    "### Retrieve sample images\n",
    "Uncomment the image fetching function you want & comment out the rest."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = get_msft_demo_images()\n",
    "# images = get_tnc_images_local()\n",
    "images = get_tnc_images_remote()\n",
    "\n",
    "draw_raw_images()"
   ]
  },
  {
   "source": [
    "### Select an image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_image = 2"
   ]
  },
  {
   "source": [
    "### Run inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call Megadetector \n",
    "\n",
    "# Each detection is: [ymin, xmin, ymax, xmax, confidence, class]\n",
    "# Image coordinates are normalized, with the origin in the upper-left\n",
    "\n",
    "r = call_megadetector(images[i_image])\n",
    "\n",
    "# print('megadetector response code: {}'.format(r))\n",
    "results,_ = response_to_json(r)\n",
    "image_name = images[i_image]['name']\n",
    "detections = results['detection_result'][image_name]\n",
    "print('Megadetector found {} object(s) in {}'.format(len(detections), image_name))\n",
    "print('{}\\n'.format(detections))\n",
    "\n",
    "# Add bounding box to image dict and call MIRA\n",
    "images[i_image]['bbox'] = detections[0][:4]\n",
    "r = call_mira(images[i_image])\n",
    "\n",
    "# print('mira response code: {}'.format(r))\n",
    "# print('response: {}'.format(r.json()))\n",
    "for key, value in r.json().items():\n",
    "    print('{} predictions: '.format(key))\n",
    "    for classification, pred in value.get('predictions').items():\n",
    "        print('{}: {}'.format(classification, pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "source": [
    "### Show results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(BytesIO(images[i_image]['data']))\n",
    "\n",
    "for detection in detections:\n",
    "    box = detection[0:4]\n",
    "    confidence = detection[4]\n",
    "    clss = detection[5]\n",
    "    if (confidence >= min_confidence_to_display):\n",
    "        draw_bounding_box_on_image(image, box[0], box[1], box[2], box[3])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}