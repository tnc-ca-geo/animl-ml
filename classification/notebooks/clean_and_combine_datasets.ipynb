{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and combine COCO datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_counts(cct):\n",
    "    '''\n",
    "    Args:\n",
    "        cct (dict): A COCO for Cameratraps JSON file parsed into dict\n",
    "\n",
    "    Returns:\n",
    "        Returns a dataframe in which each row includes a category and its respective\n",
    "        number of annotations\n",
    "    '''\n",
    "    category_map = {cct['categories'][i]['id']:cct['categories'][i]['name'] for i in range(len(cct['categories']))}\n",
    "    anns_df = pd.DataFrame(cct['annotations'])\n",
    "    counts = anns_df.groupby(['category_id']).size().reset_index(name='counts')\n",
    "    counts['category_name'] = counts['category_id'].map(category_map)\n",
    "    counts_sorted = counts.sort_values(by=['counts'], ascending=False)\n",
    "\n",
    "    # Add any categories that had a count of 0\n",
    "    for orig_cat in cct['categories']:\n",
    "        if orig_cat['id'] not in counts_sorted.category_id.values:\n",
    "            cat_to_add = pd.DataFrame([{ \n",
    "                'category_id': orig_cat['id'],\n",
    "                'counts': 0,\n",
    "                'category_name': orig_cat['name']\n",
    "            }])\n",
    "            counts_sorted = pd.concat([counts_sorted, cat_to_add], ignore_index=True)\n",
    "    \n",
    "    return counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cct(cct):\n",
    "    '''\n",
    "    Clean camera trap annotations in COCO for Cameratraps format\n",
    "    Filters out annotations (and corresponding images) that:\n",
    "      - don't have width or height data\n",
    "      - don't have bounding boxes\n",
    "      - the bbox is too large (>95% of width OR >95% height of image)\n",
    "\n",
    "    Args:\n",
    "        cct (dict): A COCO for Cameratraps JSON file parsed into dict\n",
    "\n",
    "    Returns:\n",
    "        A tuple composed of a cleaned, filtered cct dict\n",
    "        and a dict of rejects (key is reason, values are arrays of file names)\n",
    "    '''\n",
    "    print(f'No. annotations BEFORE cleaning: {len(cct[\"annotations\"])}')\n",
    "\n",
    "    image_lookup = {img['id']: img for img in cct['images']}\n",
    "\n",
    "    anns_to_keep = []\n",
    "    images_to_keep = []\n",
    "    rejects = {\n",
    "        'bad_locations': [],\n",
    "        'no_bbox': [],\n",
    "        'no_dimensions': [],\n",
    "        'bbox_too_big': [],\n",
    "    }\n",
    "\n",
    "    for annotation in cct['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        image = image_lookup.get(image_id)\n",
    "        if image is not None:\n",
    "            bbox = annotation.get('bbox')\n",
    "            width, height = image.get('width'), image.get('height')\n",
    "            if bbox is None or None in bbox:\n",
    "                rejects['no_bbox'].append(image['file_name'])\n",
    "                continue\n",
    "            if width is None or height is None:\n",
    "                rejects['no_dimensions'].append(image['file_name'])\n",
    "                continue\n",
    "            if bbox[2] >= 0.95 * width and bbox[3] >= 0.95 * height:\n",
    "                rejects['bbox_too_big'].append(image['file_name'])\n",
    "                continue\n",
    "            anns_to_keep.append(annotation)\n",
    "            images_to_keep.append(image)\n",
    "\n",
    "    # de-dupe images (b/c images to annotations is a one-to-many relationship)\n",
    "    images_df = pd.DataFrame(images_to_keep).drop_duplicates()\n",
    "    images_to_keep = images_df.to_dict('records')\n",
    "\n",
    "    print(f'No. annotations AFTER cleaning: {len(anns_to_keep)}')\n",
    "    print(f'No. images AFTER cleaning: {len(images_to_keep)}')\n",
    "    for reason, anns in rejects.items():\n",
    "        print(f'  - {len(anns)} annotations had {reason}')\n",
    "\n",
    "    return {\n",
    "      'info': cct['info'],\n",
    "      'images': images_to_keep,\n",
    "      'annotations': anns_to_keep,\n",
    "      'categories': cct['categories']\n",
    "    }, rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_categories(cct, category_map):\n",
    "    '''\n",
    "    Update and filter camera trap annotations in COCO for Cameratraps format\n",
    "    based on category_map input\n",
    "\n",
    "    Args:\n",
    "        cct (dict): A COCO for Cameratraps JSON file parsed into dict\n",
    "        category_map (list): A list of dicts that contain category info. E.g.:\n",
    "            [{'id': 1, 'name': 'occidentalis', 'keep': True, 'convert_to': 'bird'}, ...]\n",
    "\n",
    "    Returns:\n",
    "        A tuple composed of an updated, filtered cct dict,\n",
    "        a dict of rejects (key is reason, values are arrays of file names),\n",
    "        and a dict of of successful conversions, E.g.: {'<original_category>:<new_category>': <count>, ...}\n",
    "    '''\n",
    "    print(f'No. annotations BEFORE updating: {len(cct[\"annotations\"])}')\n",
    "\n",
    "    # Add new categories to category_map if necessary\n",
    "    enriched_category_map = list(category_map)\n",
    "    for cat in category_map:\n",
    "        if cat['convert_to'] == None:\n",
    "            continue\n",
    "        if cat['convert_to'] not in [cat['name'] for cat in enriched_category_map]:\n",
    "            enriched_category_map.append({\n",
    "                'id': len(enriched_category_map),\n",
    "                'name': cat['convert_to'],\n",
    "                'keep': True,\n",
    "                'convert_to': None})\n",
    "\n",
    "    image_lookup = {img['id']: img for img in cct['images']}\n",
    "    category_lookup_by_id = {cat['id']: cat for cat in enriched_category_map}\n",
    "    category_lookup_by_name = {cat['name']: cat for cat in enriched_category_map}\n",
    "\n",
    "    # update and filter annotations and images\n",
    "    anns_to_keep = []\n",
    "    images_to_keep = []\n",
    "    rejects = { 'dont_keep': [] }\n",
    "    conversions = {}\n",
    "    for annotation in cct['annotations']:\n",
    "        category_id = annotation['category_id']\n",
    "        orig_category = category_lookup_by_id.get(category_id)\n",
    "        image_id = annotation['image_id']\n",
    "        image = image_lookup.get(image_id)\n",
    "        if image is not None:\n",
    "            if orig_category.get('keep') != True:\n",
    "                # filter non-keepers\n",
    "                rejects['dont_keep'].append(image['file_name'])\n",
    "                continue\n",
    "            if orig_category.get('convert_to') is not None:\n",
    "                # convert category\n",
    "                annotation['category_id'] = category_lookup_by_name.get(orig_category.get('convert_to')).get('id')\n",
    "                conversion_key = f'{orig_category.get(\"name\")}:{orig_category.get(\"convert_to\")}'\n",
    "                if conversion_key in conversions:\n",
    "                    conversions[conversion_key] += 1\n",
    "                else:\n",
    "                    conversions[conversion_key] = 1\n",
    "            anns_to_keep.append(annotation)\n",
    "            images_to_keep.append(image)\n",
    "\n",
    "    # de-dupe images (b/c images to annotations is a one-to-many relationship)\n",
    "    images_df = pd.DataFrame(images_to_keep).drop_duplicates()\n",
    "    images_to_keep = images_df.to_dict('records')\n",
    "\n",
    "    # clean up categories\n",
    "    categories_to_keep = []\n",
    "    for cat in enriched_category_map:\n",
    "        if (cat.get('keep') == True) and (cat.get('convert_to') is None):\n",
    "            del cat['keep']\n",
    "            del cat['convert_to']\n",
    "            categories_to_keep.append(cat)\n",
    "\n",
    "    print(f'No. annotations AFTER updating: {len(anns_to_keep)}')\n",
    "    print(f'No. images AFTER updating: {len(images_to_keep)}')\n",
    "    print(f'No. categories AFTER updating: {len(categories_to_keep)}')\n",
    "    for reason, anns in rejects.items():\n",
    "        print(f'  - {len(anns)} annotations had {reason}')\n",
    "\n",
    "    return {\n",
    "      'info': cct['info'],\n",
    "      'images': images_to_keep,\n",
    "      'annotations': anns_to_keep,\n",
    "      'categories': categories_to_keep\n",
    "    }, rejects, conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Animl Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to be aware of with CCT exports from Animl:\n",
    "- the `categories` list in the export will include ALL of the Animl Project's labels, even if there aren't any examples of those labels in your exported dataset.\n",
    "- the category `id`s may be different across different COCO export attempts from Animl (even from the same project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'animl'\n",
    "home_path = os.path.expanduser('~/')\n",
    "raw_data_path = os.path.join(home_path, 'animl-ml/classification/data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animl_annotations_file = os.path.join(home_path, raw_data_path, 'animl/animl_cct.json')\n",
    "with open(animl_annotations_file, 'r') as f:\n",
    "    animl = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clean Data\n",
    "- Remove annotations with incomplete/missing data\n",
    "- normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animl_clean, rejects = clean_cct(animl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize location names (strip whitespace out make lowercase)\n",
    "\n",
    "def normalize_locations(img):\n",
    "    img['location'] = img['location'].replace(' ', '_').lower()\n",
    "    return img\n",
    "\n",
    "animl_clean['images'] = list(map(normalize_locations, animl_clean['images']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter and combine categories.\n",
    "We generate a category map to indicate which categories we want to keep and which we want to convert to something else. We then use that as an input to `update_categories()` function which cleans and updates the cct file accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2a: Inspect current sample counts for each category\n",
    "Idenify categories you may want to rename, combine with otherss, or remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the current number of samples of each category\n",
    "# NOTE: category_ids are inconsistent across different coco export attempts from Animl (even from the same project)\n",
    "\n",
    "animl_cat_counts = get_category_counts(animl_clean)\n",
    "animl_cat_counts\n",
    "\n",
    "# if it's easier to view as CSV:\n",
    "csv_file_name = os.path.join(raw_data_path, 'category_counts.csv')\n",
    "animl_cat_counts.to_csv(csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2b: Create `category_map.json` \n",
    "You'll edit this directly in the next step to indicate how you'd like to handle each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save and array of 'category' dicts with two additional fields: 'convert_to' and 'keep'\n",
    "# User copies the printed out array into code and updates each categories dict inidcated any they don't want to keep, \n",
    "# and adding 'names' of the categories they'd like to convert original categories to\n",
    "\n",
    "category_map = { 'categories': [] }\n",
    "for cat in animl_clean['categories']:\n",
    "    cat_count = animl_cat_counts.loc[animl_cat_counts['category_id'] == cat['id']]\n",
    "    category_map['categories'].append({\n",
    "      'id': cat['id'],\n",
    "      'name': cat['name'],\n",
    "      'keep': True if cat_count.counts.values[0] != 0 else False,\n",
    "      'convert_to': None\n",
    "    })\n",
    "\n",
    "# save as json file\n",
    "out_file = os.path.join(home_path, f'animl-ml/classification/data/interim/{dataset}/category_map.json')\n",
    "with open(out_file, 'w') as f:\n",
    "   json.dump(category_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2c: Edit `category_map.json`, and save it as `updated_category_map.json`\n",
    "Open the `category_map.json` file up in a text editor and modify each `category` dict, indicating whether or not you want to remove the category and filter out annotations using it (by setting `keep: false`) or convert the category to something else (`convert_to: <different_category_name>`). If you're converting a category to something else, `keep` should stay set to `true`, because you just want to rename those annotations, not remove the samples and images themselves. \n",
    "\n",
    "NOTE: you don't need to add new categories to the array if you're converting an original category to one that doesn't exist yet. The next step will handle that for you. The length of the `category_map` array should not change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2d: Load the `updated_category_map.json` and use it to update the cct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_category_map_file = os.path.join(home_path, f'animl-ml/classification/data/interim/{dataset}/updated_category_map.json')\n",
    "with open(updated_category_map_file, 'r') as f:\n",
    "    updated_category_map = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animl_filtered, rejects, conversions = update_categories(animl_clean, updated_category_map['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Dataset-specific cleaning/normalizing\n",
    "For fixing bad CCT formatting or enriching CCT \n",
    "(e.g. parsing `image['file_name']` to derive `image['location']`; modifying category IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animl_filtered['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classes\n",
    "final_animl_cat_counts = get_category_counts(animl_filtered)\n",
    "plot = final_animl_cat_counts.plot(kind=\"bar\", x=\"category_name\", y=\"counts\", title=\"DataFrame Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_animl_cat_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save cct file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json file\n",
    "out_file = os.path.join(home_path, f'animl-ml/classification/data/interim/{dataset}/animl_clean_cct.json')\n",
    "with open(out_file, 'w') as f:\n",
    "   json.dump(animl_filtered, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: everything from this point on needs to be updated and tested!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LILA Data ('rats' from Island Conservation Cameratraps dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_annotations_file = os.path.join(raw_data_path, 'island_conservation.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ic_annotations_file, 'r') as f:\n",
    "    ic = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_cat_counts = get_category_counts(ic)\n",
    "ic_cat_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset-specific cleaning\n",
    "For fixing bad CCT formatting or enriching CCT \n",
    "\n",
    "e.g. parsing `image['file_name']` to derive `image['location']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse IC's image['file_name'] to derive image['location']\n",
    "for img in ic['images']:\n",
    "    path = img['file_name'].split('/')[0:2]\n",
    "    path = '/'.join(path)\n",
    "    img['location'] = path\n",
    "\n",
    "ic['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_categories_to_keep = [7, 3, 5, 37]  # rats, iguanas, cats, pigs\n",
    "# from find_rat_locations.ipynb output:\n",
    "ic_locations_to_keep = [\n",
    "    'dominicanrepublic/camara116', 'dominicanrepublic/camara107', \n",
    "    'dominicanrepublic/camara106', 'dominicanrepublic/camara20', \n",
    "    'dominicanrepublic/camara115', 'dominicanrepublic/camara12', \n",
    "    'dominicanrepublic/camara32', 'dominicanrepublic/camara01', \n",
    "    'dominicanrepublic/camara108', 'dominicanrepublic/camara111', \n",
    "    'dominicanrepublic/camara117', 'dominicanrepublic/camara24', \n",
    "    'dominicanrepublic/camara30', 'ecuador1/ic1619', 'ecuador1/ic1616', \n",
    "    'chile/vaqueria', 'chile/frances02', 'puertorico/7a', 'puertorico/23', \n",
    "    'puertorico/2a', 'palau/cam02a', 'palau/cam09a', 'palau/cam10a', \n",
    "    'palau/cam13a', 'palau/cam14a', 'palau/cam01a', 'palau/cam04a', \n",
    "    'palau/cam06a', 'palau/cam07a', 'palau/cam08a', 'ecuador2/ic1605', \n",
    "    'ecuador2/ic1607', 'ecuador2/ic1618', 'micronesia/cam12', \n",
    "    'micronesia/cam13', 'micronesia/cam15', 'micronesia/cam03', \n",
    "    'micronesia/cam11', 'micronesia/cam10', 'micronesia/cam05', \n",
    "    'micronesia/cam08', 'micronesia/cam17', 'micronesia/cam14', \n",
    "    'micronesia/cam16', 'micronesia/cam02', 'micronesia/cam18', \n",
    "    'micronesia/cam04', 'micronesia/cam19', 'micronesia/cam06', \n",
    "    'micronesia/cam09'\n",
    "]\n",
    "\n",
    "ic_clean, rejects = clean_cct(ic, ic_categories_to_keep, ic_locations_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample rat samples from 'micronesia/cam06'\n",
    "# 'micronesia/cam06' has 10666 rats, while the location with the second highest ammount of rat samples has 640\n",
    "# the baseline model splits included micronesia/cam06 in training and seems to have learned too much about the background of that location\n",
    "img_lookup = {img['id']: img for img in ic_clean['images']}\n",
    "\n",
    "print(f'Original annotation count: {len(ic_clean[\"annotations\"])}')\n",
    "\n",
    "all_rat_annos_at_micronesiacam06 = []\n",
    "for anno in ic_clean['annotations']:\n",
    "    if anno['category_id'] == 7:\n",
    "        img = img_lookup[anno['image_id']]\n",
    "        if img['location'] == 'micronesia/cam06':\n",
    "              all_rat_annos_at_micronesiacam06.append(anno)\n",
    "\n",
    "print(f'Found {len(all_rat_annos_at_micronesiacam06)} rat annotations at micronesia/cam06')\n",
    "\n",
    "subsample_annos_at_micronesiacam06 = [anno['id'] for anno in random.sample(all_rat_annos_at_micronesiacam06, 600)]\n",
    "print(f'Subsample count: {len(subsample_annos_at_micronesiacam06)}')\n",
    "\n",
    "def subsample_fn(anno):\n",
    "    img = img_lookup[anno['image_id']]\n",
    "    if (anno['category_id'] == 7 and \n",
    "        img['location'] == 'micronesia/cam06' and\n",
    "        anno['id'] not in subsample_annos_at_micronesiacam06):\n",
    "        return False\n",
    "    else:\n",
    "        return True     \n",
    "\n",
    "ic_clean['annotations'] = list(filter(subsample_fn, ic_clean['annotations']))\n",
    "print(f'New annotation count: {len(ic_clean[\"annotations\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove known mislabed annotations\n",
    "mislabbeled_annos = [\n",
    "  '5fe812fa-df31-11ea-83e9-000d3a74c7de',\n",
    "  '674305e8-df31-11ea-aeb4-000d3a74c7de',\n",
    "  '675ff0ae-df31-11ea-9fe3-000d3a74c7de'\n",
    "]\n",
    "\n",
    "ic_clean['annotations'] = list(filter(lambda x: x['id'] not in mislabbeled_annos, ic_clean['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_cat_counts = get_category_counts(ic_clean)\n",
    "ic_cat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert IC rat category ID to Animl's\n",
    "for ann in ic_clean['annotations']:\n",
    "    if ann['category_id'] == 7: # rat (IC)\n",
    "        ann['category_id'] = 17 # rat (Animl)\n",
    "\n",
    "for cat in ic_clean['categories']:\n",
    "    if cat['id'] == 7:\n",
    "        cat['id'] = 17\n",
    "\n",
    "# ic_clean['annotations'][0]\n",
    "ic_clean['categories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets into one CCT dict\n",
    "coco_out = {}\n",
    "coco_out['images'] = animl_clean['images'] + ic_clean['images'] + buckeye_rats_clean['images']\n",
    "coco_out['annotations'] = animl_clean['annotations'] + ic_clean['annotations'] + buckeye_rats_clean['annotations']\n",
    "coco_out['categories'] = animl_clean['categories'] + ic_clean['categories']+ buckeye_rats_clean['categories'] \n",
    "coco_out['categories'] = [dict(t) for t in {tuple(d.items()) for d in coco_out['categories']}] # dedupe any dupliacte classes\n",
    "coco_out['info'] = animl_clean['info']\n",
    "\n",
    "print(f'combined dataset contains {len(coco_out[\"annotations\"])} annotations in {len(coco_out[\"images\"])} images of the following categories: \\n {list(map(lambda x: x[\"name\"], coco_out[\"categories\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_out['categories'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert len(coco_out[\"annotations\"]) == len(animl_clean[\"annotations\"]) + len(ic_clean[\"annotations\"]) + len(buckeye_rats_clean[\"annotations\"])\n",
    "assert len(coco_out[\"images\"]) == len(animl_clean[\"images\"]) + len(ic_clean[\"images\"]) + len(buckeye_rats_clean[\"images\"])\n",
    "final_cat_counts = get_category_counts(coco_out)\n",
    "final_cat_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_clean['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_out['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_counts['counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_counts['pct_of_total'] = (final_cat_counts['counts'] / final_cat_counts['counts'].sum()) * 100\n",
    "final_cat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the species distribution from the all data \n",
    "sns.barplot(data=final_cat_counts, x='category_name', y='counts')\n",
    "# add labels and species numbers\n",
    "# add number to each species\n",
    "\n",
    "plt.xlabel('category_name')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Distribution of Animal Species in the Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json file\n",
    "out_file = os.path.join(home_path, f'invasive-animal-detection/data/interim/{dataset}/combined_cct.json')\n",
    "with open(out_file, 'w') as f:\n",
    "   json.dump(coco_out, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cameratraps-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
