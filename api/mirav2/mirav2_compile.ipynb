{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MIRAv2 weights into PyTorch and compiling to Torchscript\n",
    "\n",
    "Things to note: \n",
    "- the model was trained on a GPU so we need to load weights and re-compile to CPU\n",
    "- it's important to check what version of torchvision (if used here) and torch you're running in this notebook environment & be sure they match the versions pinned in the deployment container's Dockerfile\n",
    "- it's important to know which version of efficientnet was used in training (in our case it was \"efficientnet-b3\") and the size of the inputs (in our case 300x300). See [model options and parameters](https://github.com/microsoft/CameraTraps/blob/ccb5e98095cf81a625bf19129cb3dc97354f6284/classification/efficientnet/utils.py#L452) if you don't know what size images where used in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"model-weights/ckpt_18.pt\", map_location=torch.device(\"cpu\"))\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b3\", num_classes=5)\n",
    "model.load_state_dict(ckpt['model'])\n",
    "\n",
    "# NOTE: I had originally tried the following (based on examples online) but it didn't work: \n",
    "\n",
    "# state_dict = torch.load(\"model-weights/ckpt_18.pt\", map_location=torch.device(\"cpu\"))\n",
    "# model = EfficientNet.from_pretrained(\"efficientnet-b3\", num_classes=5)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# because in Microsoft's code when they're saving checkpoints they nest the state_dict in an object w/ a key \n",
    "# called “model”: https://github.com/microsoft/CameraTraps/blob/ccb5e98095cf81a625bf19129cb3dc97354f6284/classification/train_classifier.py#L419\n",
    "# And then load it from that key: https://github.com/microsoft/CameraTraps/blob/ccb5e98095cf81a625bf19129cb3dc97354f6284/classification/train_classifier.py#L254\n",
    "\n",
    "# It's worth mentioning because if you're trying to load weights from a \n",
    "# different PyTorch model that was saved differently, \n",
    "# you may need to update this code slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/microsoft/CameraTraps/blob/ccb5e98095cf81a625bf19129cb3dc97354f6284/classification/evaluate_model.py#L71\n",
    "img_size = 300\n",
    "compiled_path = './model-weights/mira_compiled_cpu.pt'\n",
    "\n",
    "model.set_swish(memory_efficient=False)\n",
    "ex_img = torch.rand(1, 3, img_size, img_size)\n",
    "scripted_model = torch.jit.trace(model, (ex_img,))\n",
    "\n",
    "scripted_model.save(compiled_path)\n",
    "print('Saved TorchScript compiled model to', compiled_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
