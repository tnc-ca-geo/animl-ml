{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving sdzwa-andesv1 classifer with Sagemaker Serverless\n",
    "\n",
    "This nb is adapted from \n",
    "https://github.com/aws-samples/amazon-sagemaker-endpoint-deployment-of-fastai-model-with-torchserve\n",
    "\n",
    "It takes an existing .mar torchserve package from the animl-model-zoo, places it in a prod bucket, and serves it with a Sagemaker Serverless Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, time, json\n",
    "from PIL import Image\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "region = sess.region_name\n",
    "account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Role\n",
    "\n",
    "**Note**: make sure the IAM role has:  \n",
    "- `AmazonS3FullAccess`  \n",
    "- `AmazonEC2ContainerRegistryFullAccess`  \n",
    "- `AmazonSageMakerFullAccess`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Elastic Container Registry (ECR)\n",
    "\n",
    "**Note**: create ECR if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry_name = \"torchserve-sdzwa-andesv1-sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws ecr create-repository --repository-name {registry_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = f\"{account}.dkr.ecr.{region}.amazonaws.com/{registry_name}:latest\"\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Model Artifact\n",
    "\n",
    "Create a compressed `*.tar.gz` file from the `*.mar` file per requirement of Amazon SageMaker and upload the model to your Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_prefix = 'sdzwa-andesv1'\n",
    "model_uri = f's3://animl-model-zoo/{model_prefix}/{model_prefix}.mar'\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = 'torchserve'\n",
    "prod_model_uri = f\"s3://{bucket_name}/{prefix}/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prod_model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {model_uri} ./\n",
    "\n",
    "!tar cvfz {model_prefix}.tar.gz {model_prefix}.mar\n",
    "\n",
    "!aws s3 cp {model_prefix}.tar.gz {prod_model_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build a TorchServe Docker container and push it to Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skip this step if the registry is already made and the custom latest pytorch container is already pushed since this step takes a couple of minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account}.dkr.ecr.{region}.amazonaws.com\n",
    "!docker build -t {registry_name} .\n",
    "!docker tag {registry_name} {image}\n",
    "!docker push {image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = f\"{prod_model_uri}{model_prefix}.tar.gz\"\n",
    "model_already_created = False\n",
    "for model_def in sm.list_models()['Models']:\n",
    "    if model_prefix == model_def['ModelName']:\n",
    "        create_model_response = model_def\n",
    "        model_already_created = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = {\"Image\": image, \"ModelDataUrl\": model_data}\n",
    "\n",
    "if not model_already_created:\n",
    "    create_model_response = sm.create_model(\n",
    "        ModelName=model_prefix, ExecutionRoleArn=role, PrimaryContainer=container\n",
    "    )\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint configuration\n",
    "\n",
    "**Note**: choose your preferred `InstanceType`: https://aws.amazon.com/sagemaker/pricing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serverless Config (this adds the serverless config section and removes instance type and size specs from the original notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# for batch endpoints, use concurrency of 80, for real-time endpoints, use 20\n",
    "# https://github.com/tnc-ca-geo/animl-api/issues/101\n",
    "concurrency = 80\n",
    "\n",
    "endpoint_config_name = f\"{model_prefix}-config-concurrency-{concurrency}\"\n",
    "#useful for testing, not production\n",
    "# + time.strftime(\n",
    "#     \"%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    "# )\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": model_prefix,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ServerlessConfig\": {\n",
    "            \"MemorySizeInMB\": 6144,\n",
    "            \"MaxConcurrency\": concurrency\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_prefix}-concurrency-{concurrency}\"\n",
    "# useful for testing not production\n",
    "# + time.strftime(\n",
    "#     \"%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    "# )\n",
    "\n",
    "print(endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "NOTE: the deployed endpoints can be a little finiky when you first deploy them. I'm not totally sure what's going on, but sometimes we get strange timeouts and opaque errors when you invoke the endpoint immediately after deploying it. If it doesn't work right out of the gate, try a few times, let the endpoint instance scale down and stop running, try cold starts/warm starts, etc. before determining something is broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import json\n",
    "# endpoint_name = \"nzdoc\"\n",
    "\n",
    "image_key = \"brazilian-tapir.jpg\"\n",
    "image_bbox = [0.0005858103395439684,0.3138456642627716,0.8546993732452393,0.9790124893188477]\n",
    "image = boto3.client(\"s3\").get_object(Bucket=\"animl-sample-images\", Key=image_key)['Body'].read()\n",
    "Image.open(BytesIO(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import base64\n",
    "image_string = base64.b64encode(image).decode('ascii')\n",
    "payload = { 'image': image_string, 'bbox': image_bbox } # bbox can either be list or string (e.g. \"[0,0,1,1]\")\n",
    "payload_encoded = json.dumps(payload).encode('utf-8')\n",
    "client = boto3.client(\"runtime.sagemaker\")\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"multipart/form-data\", Body=payload_encoded\n",
    ")\n",
    "response = json.loads(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"sagemaker\")\n",
    "client.delete_model(ModelName=sm_model_name)\n",
    "client.delete_endpoint(EndpointName=endpoint_name)\n",
    "client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### weird error, create model expects arn satisfying a different reg expression than create inf recommender. \"model\" vs \"model-package\" in the reg expression requirement.\n",
    "\n",
    "# job_name = \"mdv5-recommender\"\n",
    "# job_type = \"Default\"\n",
    "# sm.create_inference_recommendations_job(\n",
    "#     JobName = job_name,\n",
    "#     JobType = job_type,\n",
    "#     RoleArn = role,\n",
    "#     InputConfig = {\n",
    "#         'ModelPackageVersionArn': create_model_response[\"ModelArn\"]\n",
    "#     }\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
