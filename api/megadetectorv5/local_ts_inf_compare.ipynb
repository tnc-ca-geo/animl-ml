{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb461a3-67a6-462e-b7cd-5150ab46aefb",
   "metadata": {},
   "source": [
    "# Profiling speed of img size vs model type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead5dcf-21e0-46f1-8496-c7e56027b030",
   "metadata": {},
   "source": [
    "### Torchscript 1280x1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ba9a0b-5ce9-4da5-95e9-5231bf730276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 958 ms, sys: 460 ms, total: 1.42 s\n",
      "Wall time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torchvision.transforms as tf\n",
    "import torch\n",
    "from PIL import Image\n",
    "ts_model = torch.jit.load(\"./model-weights/md_v5a.0.0.1280.1280.torchscript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47a97a2-5907-43a8-9ab8-57e9c5cbbc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 577 ms, total: 13.6 s\n",
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = ts_model.forward(x = torch.randn(1, 3, 1280, 1280, requires_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2aafa3-c683-474f-9d15-20e64f76cfe1",
   "metadata": {},
   "source": [
    "### ONNX 1280x1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979ec98c-d28c-4a23-b266-23e7f5aff392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 829 ms, sys: 457 ms, total: 1.29 s\n",
      "Wall time: 996 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import onnx\n",
    "import torchvision.transforms as tf\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "ort_session = ort.InferenceSession(\"./model-weights/md_v5a.0.0.1280.1280.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08988c2-a002-42e9-9090-b5bf7e6c4ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 113 ms, total: 13.8 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\"images\": np.random.randn(1, 3, 1280, 1280).astype(np.float32)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280376-0c80-4ac5-bbec-911076ff42d4",
   "metadata": {},
   "source": [
    "### ONNX 960x1280, the winner in terms of accuracy (largely unchanged) and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29266036-42e7-4835-8f7f-b46fc43bc0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ort_session_960_1280 = ort.InferenceSession(\"./model-weights/md_v5a.0.0.960.1280.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2eaa8b-f3d7-469e-842a-05fcf1ad59ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 s, sys: 68.2 ms, total: 9.43 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = ort_session_960_1280.run(\n",
    "    None,\n",
    "    {\"images\": np.random.randn(1, 3, 960, 1280).astype(np.float32)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a7981-d26d-40a2-aa1f-41a2ea50e765",
   "metadata": {},
   "source": [
    "### Original Inference with letterbox resizing and original model weights on approx 960,1280 img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2b7b061-2ffb-4b24-a633-780a96fb877a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-3-16 Python-3.9.16 torch-1.10.0+cu102 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 574 layers, 139990096 parameters, 0 gradients, 207.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 884 ms, sys: 87.2 ms, total: 972 ms\n",
      "Wall time: 970 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_num_threads(1)\n",
    "device = torch.device(\"cpu\")\n",
    "# Read model serialize/pt file\n",
    "serialized_file = \"models/md_v5a.0.0.pt\"\n",
    "\n",
    "# Model\n",
    "weights_model = torch.hub.load('./yolov5', 'custom', source = \"local\", skip_validation=True, path=serialized_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b63fa31-26b0-4ab7-b205-50c63480bf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edc93220-a86e-4528-9667-119a210df792",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): Model(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 80, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (6): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (7): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (6): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (7): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (8): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (9): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (10): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (11): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(640, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(960, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(960, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): Conv(\n",
       "          (conv): Conv2d(960, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (10): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (12): Conv(\n",
       "          (conv): Conv2d(1280, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (13): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (14): Concat()\n",
       "        (15): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1920, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1920, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (17): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (18): Concat()\n",
       "        (19): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (20): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (21): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (25): Concat()\n",
       "        (26): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (27): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (28): Concat()\n",
       "        (29): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1280, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1280, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (30): Conv(\n",
       "          (conv): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (31): Concat()\n",
       "        (32): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (33): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(320, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(640, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(960, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Conv2d(1280, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b49e6c-329f-4d8a-91bc-2c0bfe51d3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = weights_model.forward(torch.randn(1, 3, 1280, 1280, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d82e227-7465-49ba-8422-f2d45ca522c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 7.91 ms, total: 35.9 ms\n",
      "Wall time: 35.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = weights_model.forward(torch.randn(1, 3, 960, 1280, requires_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb967d-1809-42f9-8109-9451f201af30",
   "metadata": {},
   "source": [
    "## Accuracy Comparison, now that we know ONNx is most fast, what are the trade offs when \n",
    "\n",
    "* fixing aspect ratio and changing resolution with padding\n",
    "* changing aspect ratio with fixed resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3232a1e-e6a5-4dee-bc64-6dcc3f5a6342",
   "metadata": {},
   "source": [
    "## Below are a lot of funcs for pre and post processing taken from mdv5a_handler.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228a6201-3499-443f-946c-c48e72f74749",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import torchvision\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "img_size = 1280\n",
    "min_conf_thresh = 0.00001\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    \"\"\"Converts input images to float tensors.\n",
    "    Args:\n",
    "        data (List): Input data from the request in the form of a list of image tensors.\n",
    "    Returns:\n",
    "        Tensor: single Tensor of shape [BATCH_SIZE=1, 3, IMG_SIZE, IMG_SIZE]\n",
    "    \"\"\"\n",
    "    # force convert to tensor\n",
    "    # and resize to [img_size, img_size]\n",
    "    image = np.asarray(image)\n",
    "    original_image_shape = image.shape\n",
    "    image, ratio, dw_dh = letterbox(image, new_shape=img_size,\n",
    "                stride=64, auto=True)  # JIT requires auto=False\\\n",
    "    letterbox_shape = image.shape\n",
    "    image = image.transpose((2, 0, 1))  # HWC to CHW; PIL Image is RGB already\n",
    "    image = np.ascontiguousarray(image)\n",
    "    image = torch.from_numpy(image)\n",
    "    # image = image.to(self.device)\n",
    "    image = image.float()\n",
    "    image /= 255\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    # has shape BATCH_SIZE=1 x 3 x IMG_SIZE x IMG_SIZE\n",
    "    return image, original_image_shape, letterbox_shape, ratio, dw_dh\n",
    "\n",
    "def preprocess_onnx(image):\n",
    "    \"\"\"Converts input images to float tensors.\n",
    "    Args:\n",
    "        data (List): Input data from the request in the form of a list of image tensors.\n",
    "    Returns:\n",
    "        Tensor: single Tensor of shape [BATCH_SIZE=1, 3, IMG_SIZE, IMG_SIZE]\n",
    "    \"\"\"\n",
    "    # force convert to tensor\n",
    "    # and resize to [img_size, img_size]\n",
    "    image = np.asarray(image)\n",
    "    original_image_shape = image.shape\n",
    "    image, ratio, dw_dh = letterbox(image, new_shape=(960,1280),\n",
    "                stride=64, scaleup=False, auto=False)  # JIT requires auto=False\\\n",
    "    letterbox_shape = image.shape\n",
    "    image = image.transpose((2, 0, 1))  # HWC to CHW; PIL Image is RGB already\n",
    "    image = np.ascontiguousarray(image)\n",
    "    image = torch.from_numpy(image)\n",
    "    # image = image.to(self.device)\n",
    "    image = image.float()\n",
    "    image /= 255\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    # has shape BATCH_SIZE=1 x 3 x IMG_SIZE x IMG_SIZE\n",
    "    return image, original_image_shape, letterbox_shape, ratio, dw_dh\n",
    "\n",
    "def postprocess(inference_output, original_image_shape, letterbox_shape, ratio, dw_dh):\n",
    "    # perform NMS (nonmax suppression) on model outputs\n",
    "    pred = non_max_suppression(inference_output, conf_thres=min_conf_thresh, iou_thres=.45)\n",
    "\n",
    "    # initialize empty list of detections for each image\n",
    "    detections = [[] for _ in range(len(pred))]\n",
    "\n",
    "    for i, image_detections in enumerate(pred):  # axis 0: for each image\n",
    "        for det in image_detections:  # axis 1: for each detection\n",
    "            if dw_dh[0] == 0 and dw_dh[1] == 0:\n",
    "                det[:4] = scale_boxes(letterbox_shape, det[:4], original_image_shape)\n",
    "            else:\n",
    "                det[:4] = scale_boxes(letterbox_shape, det[:4], original_image_shape, (ratio, dw_dh))\n",
    "\n",
    "            # x1,y1,x2,y2 in normalized image coordinates (i.e. 0.0-1.0)\n",
    "            xyxy = det[:4] / img_size\n",
    "            # confidence value\n",
    "            conf = det[4].item()\n",
    "            # index of predicted class\n",
    "            class_idx = int(det[5].item())\n",
    "            detections[i].append({\n",
    "                \"x1\": xyxy[0].item(),\n",
    "                \"y1\": xyxy[1].item(),\n",
    "                \"x2\": xyxy[2].item(),\n",
    "                \"y2\": xyxy[3].item(),\n",
    "                \"confidence\": conf,\n",
    "                \"class\": class_idx + 1 # schema we use is 1 for animal, 2 for person, 3 for vehicle\n",
    "            })\n",
    "\n",
    "    # format each detection\n",
    "    return detections\n",
    "\n",
    "\n",
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n",
    "                        labels=(), max_det=1000):\n",
    "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n",
    "    Returns:\n",
    "         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
    "    \"\"\"\n",
    "\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "    xc = prediction[..., 4] > conf_thres  # candidates\n",
    "\n",
    "    # Checks\n",
    "    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
    "    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
    "\n",
    "    # Settings\n",
    "    # (pixels) minimum and maximum box width and height\n",
    "    min_wh, max_wh = 2, 4096\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 10.0  # seconds to quit after\n",
    "    redundant = True  # require redundant detections\n",
    "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "    merge = False  # use merge-NMS\n",
    "\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)\n",
    "              ] * prediction.shape[0]\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[xc[xi]]  # confidence\n",
    "\n",
    "        # Cat apriori labels if autolabelling\n",
    "        if labels and len(labels[xi]):\n",
    "            l = labels[xi]\n",
    "            v = torch.zeros((len(l), nc + 5), device=x.device)\n",
    "            v[:, :4] = l[:, 1:5]  # box\n",
    "            v[:, 4] = 1.0  # conf\n",
    "            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
    "            x = torch.cat((x, v), 0)\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[\n",
    "                conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Apply finite constraint\n",
    "        # if not torch.isfinite(x).all():\n",
    "        #     x = x[torch.isfinite(x).all(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            # sort by confidence\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        # boxes (offset by class), scores\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
    "            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
    "            iou = torchvision.box_iou(\n",
    "                boxes[i], boxes) > iou_thres  # iou matrix\n",
    "            weights = iou * scores[None]  # box weights\n",
    "            x[i, :4] = torch.mm(weights, x[:, :4]).float(\n",
    "            ) / weights.sum(1, keepdim=True)  # merged boxes\n",
    "            if redundant:\n",
    "                i = i[iou.sum(1) > 1]  # require redundancy\n",
    "\n",
    "        output[xi] = x[i]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, ratio, (dw, dh)\n",
    "\n",
    "def open_image(input_file):\n",
    "    \"\"\"\n",
    "    Opens an image in binary format using PIL.Image and converts to RGB mode.\n",
    "    \n",
    "    Supports local files or URLs.\n",
    "    This operation is lazy; image will not be actually loaded until the first\n",
    "    operation that needs to load it (for example, resizing), so file opening\n",
    "    errors can show up later.\n",
    "    Args:\n",
    "        input_file: str or BytesIO, either a path to an image file (anything\n",
    "            that PIL can open), or an image as a stream of bytes\n",
    "    Returns:\n",
    "        an PIL image object in RGB mode\n",
    "    \"\"\"\n",
    "    if (isinstance(input_file, str)\n",
    "            and input_file.startswith(('http://', 'https://'))):\n",
    "        try:\n",
    "            response = requests.get(input_file)\n",
    "        except Exception as e:\n",
    "            print(f'Error retrieving image {input_file}: {e}')\n",
    "            success = False\n",
    "            if e.__class__.__name__ in error_names_for_retry:\n",
    "                for i_retry in range(0,n_retries):\n",
    "                    try:\n",
    "                        time.sleep(retry_sleep_time)\n",
    "                        response = requests.get(input_file)        \n",
    "                    except Exception as e:\n",
    "                        print(f'Error retrieving image {input_file} on retry {i_retry}: {e}')\n",
    "                        continue\n",
    "                    print('Succeeded on retry {}'.format(i_retry))\n",
    "                    success = True\n",
    "                    break\n",
    "            if not success:\n",
    "                raise\n",
    "        try:\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        except Exception as e:\n",
    "            print(f'Error opening image {input_file}: {e}')\n",
    "            raise\n",
    "\n",
    "    else:\n",
    "        image = Image.open(input_file)\n",
    "    if image.mode not in ('RGBA', 'RGB', 'L', 'I;16'):\n",
    "        raise AttributeError(\n",
    "            f'Image {input_file} uses unsupported mode {image.mode}')\n",
    "    if image.mode == 'RGBA' or image.mode == 'L':\n",
    "        # PIL.Image.convert() returns a converted copy of this image\n",
    "        image = image.convert(mode='RGB')\n",
    "\n",
    "    # Alter orientation as needed according to EXIF tag 0x112 (274) for Orientation\n",
    "    #\n",
    "    # https://gist.github.com/dangtrinhnt/a577ece4cbe5364aad28\n",
    "    # https://www.media.mit.edu/pia/Research/deepview/exif.html\n",
    "    #\n",
    "    try:\n",
    "        exif = image._getexif()\n",
    "        orientation: int = exif.get(274, None)  # 274 is the key for the Orientation field\n",
    "        if orientation is not None and orientation in IMAGE_ROTATIONS:\n",
    "            image = image.rotate(IMAGE_ROTATIONS[orientation], expand=True)  # returns a rotated copy\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_image(input_file):\n",
    "    \"\"\"\n",
    "    Loads the image at input_file as a PIL Image into memory.\n",
    "    Image.open() used in open_image() is lazy and errors will occur downstream\n",
    "    if not explicitly loaded.\n",
    "    Args:\n",
    "        input_file: str or BytesIO, either a path to an image file (anything\n",
    "            that PIL can open), or an image as a stream of bytes\n",
    "    Returns: PIL.Image.Image, in RGB mode\n",
    "    \"\"\"\n",
    "    image = open_image(input_file)\n",
    "    image.load()\n",
    "    return image\n",
    "\n",
    "#from yolov5\n",
    "def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None):\n",
    "    # Rescale boxes (xyxy) from img1_shape to img0_shape\n",
    "    if ratio_pad is None:  # calculate from img0_shape\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
    "    else:\n",
    "        gain = ratio_pad[0][0]\n",
    "        pad = ratio_pad[1]\n",
    "    boxes[..., [0, 2]] -= pad[0]  # x padding\n",
    "    boxes[..., [1, 3]] -= pad[1]  # y padding\n",
    "    boxes[..., :4] /= gain\n",
    "    clip_boxes(boxes, img0_shape)\n",
    "    return boxes\n",
    "\n",
    "def clip_boxes(boxes, shape):\n",
    "    # Clip boxes (xyxy) to image shape (height, width)\n",
    "    if isinstance(boxes, torch.Tensor):  # faster individually\n",
    "        boxes[..., 0].clamp_(0, shape[1])  # x1\n",
    "        boxes[..., 1].clamp_(0, shape[0])  # y1\n",
    "        boxes[..., 2].clamp_(0, shape[1])  # x2\n",
    "        boxes[..., 3].clamp_(0, shape[0])  # y2\n",
    "\n",
    "    else:  # np.array (faster grouped)\n",
    "        boxes[..., [0, 2]] = boxes[..., [0, 2]].clip(0, shape[1])  # x1, x2\n",
    "        boxes[..., [1, 3]] = boxes[..., [1, 3]].clip(0, shape[0])  # y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f5cdd39-3e2b-4c5c-bb96-ac8860c792c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#test_dir = '../../input/md-rodent-false-negatives/'\n",
    "test_dir = '../../input/coolpics/'\n",
    "fnegs_dir = Path(test_dir)\n",
    "imgs = [str(i) for i in fnegs_dir.glob(\"**/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a48b9e67-011a-4cb7-a77f-e04bf747496b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from dask import delayed\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b760ee8-ff93-4728-8981-39545bc16130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 774.36 us"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 3.15 sms\n",
      "[########################################] | 100% Completed | 3.25 s\n"
     ]
    }
   ],
   "source": [
    "per_im_results = []\n",
    "for pth in tqdm(imgs):\n",
    "    img = open_image(pth)\n",
    "    resized_img, original_image_shape, letterbox_shape, ratio, dw_dh = preprocess(img)\n",
    "    per_im_results.append((delayed(weights_model.forward)(resized_img), original_image_shape, letterbox_shape, ratio, dw_dh))\n",
    "    \n",
    "\n",
    "inference_results_model_weights = dask.compute(per_im_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8683fc45-e60a-4e2f-b1bc-66cb40275fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, result in enumerate(inference_results_model_weights[0]):\n",
    "    results.update({str(imgs[i]).split(\"/\")[-1]:postprocess(result[0], original_image_shape = result[1], letterbox_shape =result[2], ratio=result[3], dw_dh=result[4])})\n",
    "\n",
    "top_results_model_weights = {}\n",
    "for k,v in results.items():\n",
    "    top_results_model_weights.update({k: v[0][0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b302df-3500-4ef1-8755-8e03af328a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00, 18.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 82.55 uss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 56.35 s\n",
      "[########################################] | 100% Completed | 56.45 s\n"
     ]
    }
   ],
   "source": [
    "per_im_results = []\n",
    "for pth in tqdm(imgs):\n",
    "    img = open_image(pth)\n",
    "    resized_img, original_image_shape, letterbox_shape, ratio, dw_dh = preprocess_onnx(img)\n",
    "    per_im_results.append((delayed(ort_session_960_1280.run)(None,\n",
    "                                                                {\"images\": resized_img.numpy().astype(np.float32)},\n",
    "                                                            ), original_image_shape, letterbox_shape,  ratio, dw_dh))\n",
    "    \n",
    "\n",
    "inference_results_model_weights = dask.compute(per_im_results)\n",
    "\n",
    "results_onnx = {}\n",
    "for i, result in enumerate(inference_results_model_weights[0]):\n",
    "    results_onnx.update({str(imgs[i]).split(\"/\")[-1]:postprocess(torch.Tensor(result[0][0]), original_image_shape = result[1], letterbox_shape =result[2], ratio=result[3], dw_dh=result[4])})\n",
    "\n",
    "top_results_onnx = {}\n",
    "for k,v in results_onnx.items():\n",
    "    top_results_onnx.update({k: v[0][0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176f3f1-eb57-488d-b273-a50446b807fb",
   "metadata": {},
   "source": [
    "# Comparing confidence scores of ONNX with fixed size resizing vs non-fixed resizing with model state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a28aedae-723e-4ec6-b712-1336d6667681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGeCAYAAAC3nVoKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkPElEQVR4nO3deXBUVf7+8adDTAMhIQEEAokJMECURRARURkWWYZNERHRmQJlICKKIqJF3DAuBGVY3BAXxBXFMCIwsiPlMgEcdVxAwriABoKFQOgWgQ4m5/eH3/QvoQNpOp3cE3i/qm6Vfe6Szz33zPh4V5cxxggAAMBiEU4XAAAAUB4CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAepFOFxAORUVFysvLU0xMjFwul9PlAACAIBhj9Ouvv6pJkyaKiDj5OZTTIrDk5eUpKSnJ6TIAAEAIcnNzlZiYeNJlTovAEhMTI+mPHY6NjXW4GgAAEAyv16ukpCT/v8dP5rQILMWXgWJjYwksAABUM8HczsFNtwAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAetYElldeeUUdO3ZUzZo11aBBA/Xv319HjhxxuiwAAGABK17N/+ijj+qxxx7TPffco65du2rfvn1av369CgsLnS4NAABYwGWMMU4WsH37drVt21bLli1T//79Q9qG1+tV3bp15fF4+JYQAADVxKn8+9vxS0ILFixQs2bNQg4rAADg9Od4YNm0aZPatWunRx55RA0bNlRUVJQuvfRSbd68+YTr+Hw+eb3eUhMAADh9OX4Py88//6zPPvtMX3/9tebOnavatWtr2rRp6tu3r7799ls1bNgwYJ3MzExlZGQ4UC0AoLpJmfJeucvsnD6wCipBRTh+hqWoqEiHDh3S4sWLNWzYMA0YMEDLli2TMUZPP/10meukp6fL4/H4p9zc3CquGgAAVCXHz7DEx8erfv36at++vb+tXr166tixo7Zu3VrmOm63W263u6pKBAAADnP8DEubNm1OOO/o0aNVWAkAALCV44Fl0KBB2r9/v7744gt/2/79+/X555+rU6dOzhUGAACs4XhgGTJkiDp37qxhw4Zp0aJFWrZsmQYNGiS3263x48c7XR4AALCA44ElIiJCK1asUNeuXXXTTTdpxIgRio2N1YcffqjGjRs7XR4AALCA4zfdSlKDBg302muvOV0GAACwlONnWAAAAMpDYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6jgeWl19+WS6XK2CaMmWK06UBAABLRDpdQLFVq1apbt26/t9NmzZ1sBoAAGATawJLp06d1KBBA6fLAAAAFnL8khAAAEB5rAksbdq0UY0aNdS8eXNlZmaqsLDQ6ZIAAIAlHL8klJCQoIyMDHXp0kUul0vLli3Tfffdp927d+vpp58ucx2fzyefz+f/7fV6q6pcAADgAMcDS79+/dSvXz//7759+6pWrVqaPXu27r33XiUkJASsk5mZqYyMjKosEwAAOMiaS0IlDR8+XIWFhfriiy/KnJ+eni6Px+OfcnNzq7ZAAABQpRw/wxIKt9stt9vtdBkAAKCKWHmG5a233lKNGjXUsWNHp0sBAAAWcPwMS79+/dSrVy+1a9dOkrRs2TI9//zzuv3229W4cWOHqwMAADZwPLCkpqZq/vz52rVrl4qKitSqVSvNmTNHEyZMcLo0AABgCccDyxNPPKEnnnjC6TIAAIDFrLyHBQAAoCQCCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOtZFVgOHTqkxMREuVwuffrpp06XAwAALGFVYHn44Yf1+++/O10GAACwjDWBJScnR88884wyMjKcLgUAAFjGmsAyYcIEjRs3Tq1bt3a6FAAAYBkrAsvixYv19ddf64EHHnC6FAAAYKFIpws4fPiwJk2apGnTpik2NjaodXw+n3w+n/+31+utrPIAAIAFHA8sjzzyiBo1aqQbb7wx6HUyMzO51wUALJUy5b1yl9k5fWAVVBJep+t+VReOXhL68ccfNXPmTGVkZMjj8ejgwYM6dOiQpD8ecS7+5+Olp6fL4/H4p9zc3KosGwAAVDFHz7Ds2LFDBQUFGjgwMJH27NlTXbp00aZNmwLmud1uud3uqigRAABYwNHA0qFDB23YsKFU2xdffKE77rhD8+bNU+fOnR2qDAAA2MTRwBIXF6cePXqUOa9Tp0664IILqrYgAABgJSseawYAADgZx58SOl6PHj1kjHG6DAAAYBHOsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWC/kwDJlyhR9++234awFAACgTCEHltdee02pqanq1q2bXnnlFR0+fDicdQEAAPiFHFhyc3O1bNkyNWrUSGlpaUpISFBaWpo2btwYzvoAAABCDywREREaOHCgFi9erLy8PGVkZOiTTz7RZZddpjZt2mjmzJnau3dvOGsFAABnqLDcdFu/fn1NnDhRr776qrp166Zt27bprrvuUlJSkkaNGqVffvklHH8GAACcoSocWDwej5599lldeOGF6tixo7xer5555hnl5eXp2Wef1UcffaQRI0aEo1YAAHCGCvnjh+vXr9dLL72kd999V5GRkbruuuv03HPPqVOnTv5lRo8eraSkJA0ePDgsxQIAgDNTyIGlT58+6tKli5566imNGDFCtWvXLnO5Vq1a6brrrgu5QAAAgJADy1dffaW2bduWu1xycrIWLFgQ6p8BAAAI/R6W5ORk7dmzp8x5e/bs0aFDh0IuCgAAoKSQz7CMGTNGMTExevHFFwPmTZ06VYcOHdLChQsrVBwAAIBUgTMsH374oQYOHFjmvAEDBuiDDz4IuSgAAICSQg4s+fn5iomJKXNedHS09u/fH3JRAAAAJYUcWJo3b65169aVOW/9+vVKSUkJddMAAAClhBxYxowZo1mzZunxxx/Xvn37JEn79u3TjBkzNHv2bI0dOzZsRQIAgDNbyDfd3nHHHfr++++Vnp6u9PR0RUZG6vfff5ckjRs3TnfeeWfYigQAAGe2kAOLy+XSM888o4kTJ2r9+vU6cOCA6tevr169eqlly5bhrBEAAJzhQg4sxVq2bElAAQAAlapCgaWwsFCbN2/Wrl27dPTo0YD5I0eOrMjmAQAAJFUgsHz++ecaOnSocnNzZYwJmO9yuQgsAAAgLEIOLDfffLPq1q2rV155Reedd56ioqLCWRcAAIBfyIFl69atysrKUvfu3cNZDwAAQICQ38PSqlUreb3ecNYCAABQppADy+zZs5WZmamcnJxw1gMAABAg5EtCt956q37++We1bdtWTZo0UVxcXKn5LpdLX375ZUXrAwAACD2wdOrUSS6XK5y1AAAAlCnkwPLyyy+HsQwAAIATC/kelpKMMcrLy/N/SwgAACCcKhRYVq9erYsvvlg1a9ZUUlKSvvrqK0lSWlqa3njjjbAUCAAAEHJgefPNNzVgwAA1a9ZMc+fOLfW22xYtWmjBggVhKRAAACDkwPLwww9r4sSJevPNN3XDDTeUmtemTRtt2bKlorUBAABIqkBg+eGHHzRgwIAy50VHR8vj8YRcFAAAQEkhB5bGjRuf8KVxX331lZKTk0MuCgAAoKSQA8v111+vBx98UOvXr/e3uVwubdmyRY8//rj+9re/haVAAACAkN/D8uCDD2rr1q3q06eP6tevL0nq37+/fvnlFw0aNEhTpkwJW5EAAODMFnJgiYqK0tKlS7VhwwatXbtW+/btU7169dS7d2/17t07nDUCAIAzXMiBpVjPnj3Vs2fPcNQCAABQppADy08//VTuMuecc06omwcAAPALObCkpKSU+/HDwsLCUDcPAADgF3JgWbJkSUBbfn6+Vq9erU2bNmn69OkVKgwAAKBYyIHlyiuvLLP9hhtu0KRJk/TBBx/o2muvLXc7K1as0GOPPaZvvvlGXq9XTZs21ZAhQzR16lTVrVs31PIAAMBpJCxfaz7egAED9NZbbwW17IEDB9SlSxfNmzdPq1ev1qRJk/Tqq6/qmmuuqYzSAABANVThp4TKkp2drZo1awa17PEvmOvRo4fcbrfS0tKUl5enJk2aVEaJAACgGgk5sNx2220BbQUFBdq2bZs+/vhjTZ48OeSiil9EV1BQEPI2AADA6SPkwLJ8+fKAtpo1ayoxMVFz587VmDFjTml7hYWFOnbsmL755hs99NBDuuKKK5SSklLmsj6fTz6fz//b6/We0t8CAADVS8iBZceOHeGsQ8nJydq9e7ck6S9/+YsWLlx4wmUzMzOVkZER1r8PAADsVSk33YZixYoVys7O1gsvvKBt27Zp8ODBJ3yPS3p6ujwej3/Kzc2t4moBAEBVCvkMy0MPPRT0si6XS/fff/9Jl2nfvr0kqWvXrurcubM6dOigJUuWaNiwYQHLut1uud3uUysYAABUWyEHltmzZ6ugoEBHjhyR9Mf9K0ePHpUk1apVS1FRUf5lgwksJbVv315nnXWWvvvuu1DLAwAAp5GQLwmtXbtWjRo10vz58+XxeHT48GF5PB69+OKLatSokdasWaP8/Hzl5+frwIEDp7TtzZs369ixY2revHmo5QEAgNNIyGdYbr31Vt1111268cYb/W0xMTEaPXq0jhw5oltuuUWffPJJudsZOnSoLrzwQrVv3161atXSl19+qRkzZqh9+/YaMmRIqOUBAIDTSMiB5csvv1SzZs3KnNeiRQtt2bIlqO1cdNFFWrRokaZPn66ioiKlpKRo7Nixmjx5cqnLSgAA4MxVoa81z5s3T/369Sv11WZjjObOnavk5OSgtjNlyhRNmTIl1DIAAMAZIOTAMn36dA0bNkwtW7bU4MGD1bBhQ+3du1fLly/Xjz/+qMWLF4ezTgAAcAar0Nea//Of/2j69OlaunSp9uzZo4SEBF100UVavHixOnToEMYyAQDAmaxCHz/s0KFD0F9lBgAACFVY3nSbm5ur7Oxs/fbbb+HYHAAAQCkVCizPP/+8mjZtquTkZHXr1k3bt2+XJF111VV64oknwlIgAABAyIFlzpw5mjBhgkaOHKk1a9bIGOOf16NHD2VlZYWlQAAAgJDvYXnqqad0//3367777gv4SGHr1q39Z1sAAAAqKuQzLLt379Yll1xS5ryzzjpLhw4dCrkoAACAkkIOLMnJySd89f7mzZvVqlWrkIsCAAAoKeTAMnbsWD3yyCOaP3++vF6vJOnYsWN67733NGPGDN10001hKxIAAJzZQr6HZfLkyfrpp5+UlpbmDyeXXnqpJGn8+PEaP358eCoEAABnvAq9OO7JJ5/UxIkTtW7dOu3bt0/16tXT5ZdfrpYtW4arPgAAgNACy9GjR9WoUSO9/vrrGjx4sNLS0sJdFwAAgF9I97DUrFlTtWvXVmRkhU7QAAAABCXkm25HjRqlF198MZy1AAAAlCnkUyTx8fHatGmT2rVrp/79+6tRo0ZyuVz++S6XS3fccUdYigQAAGe2kANLenq6JGnPnj3aunVrwHwCCwAACJdTuiTUvn17bdmyRZJUVFSkoqIivfbaa9q/f7//d/F0/Ov6AQAAQnVKgWXLli06fPiw/3dhYaFGjhypHTt2hL0wAACAYiHfdFus5FeaAQAAKkOFAwsAAEBlO+XAUvJJoJO1AQAAhMspPyXUs2dPRUSUzjndunULaHO5XPJ4PBWrDgAAQKcYWKZOnVpZdQAAAJwQgQUAAFiPm24BAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwnuOBJSsrS1deeaUSExMVHR2tDh066KWXXpIxxunSAACAJSKdLmDWrFlKSUnRzJkzdfbZZ2vt2rUaO3ascnNzNXXqVKfLAwAAFnA8sCxfvlwNGjTw/+7Vq5f279+vWbNm6f7771dEhOMngQAAgMMcTwMlw0qxjh07yuv16rfffnOgIgAAYBvHA0tZPv74YzVt2lQxMTFOlwIAACzg+CWh43388cd66623NHPmzBMu4/P55PP5/L+9Xm9VlAYAABxiVWDZtWuXrr32WvXs2VO33XbbCZfLzMxURkZGFVYGAKcmZcp75S6zc/rAKqgkeKdrzVW5HVQeay4JHTx4UP3791f9+vX1z3/+86Q326anp8vj8fin3NzcKqwUAABUNSvOsBw5ckSDBg2Sx+PRxo0bVbdu3ZMu73a75Xa7q6g6AADgNMcDy++//67hw4dr27Zt+uijj9S0aVOnSwIAAJZxPLCMHz9e//rXvzRz5kx5vV5t2rTJP69jx46cSQEAAM4HljVr1kiS7rzzzoB5O3bsUEpKShVXBAAAbON4YNm5c6fTJQAAAMtZ85QQAADAiRBYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWM/xwPLdd99p3Lhx6tChgyIjI9W2bVunSwIAAJaJdLqArVu36r333lOXLl1UVFSkoqIip0sCAACWcfwMy+DBg5Wbm6vFixfrggsucLocAABgIccDS0SE4yUAAADLkRYAAID1HL+HJRQ+n08+n8//2+v1OlgNAACobNUysGRmZiojI6PK/l7KlPfKXWbn9IFVUAlQcdVxPAdTczBs26/qKFzHwra/FS62jVXb6qmIanlJKD09XR6Pxz/l5uY6XRIAAKhE1fIMi9vtltvtdroMAABQRarlGRYAAHBmcfwMy+HDh7VixQpJ0o8//iiv16vFixdLkrp3766zzz7byfIAAIAFHA8se/fu1TXXXFOqrfj3hg0b1KNHDweqAgAANnE8sKSkpMgY43QZAADAYtzDAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0rAktOTo769Omj6OhoNW7cWHfffbcKCgqcLgsAAFgi0ukC8vPz1atXL7Vs2VLvvPOOdu/erUmTJunw4cN6+umnnS4PAABYwPHAMm/ePHm9Xi1ZskT16tWTJP3+++8aP3687rnnHjVp0sThCgEAgNMcvyS0cuVK9e7d2x9WJGn48OEqKirSmjVrHKwMAADYwvEzLDk5ORo9enSptri4OCUkJCgnJ6fMdXw+n3w+n/+3x+ORJHm93kqpsch3uNxlKutvA+FWHcdzMDUHoyr360zu52AEs+9VWY9twjU2bP/fTvF2jTHlL2wcFhkZaTIzMwPa27RpY8aOHVvmOlOnTjWSmJiYmJiYmE6DKTc3t/y8oGooPT1dkyZN8v8uKirSgQMHVL9+fblcriqtxev1KikpSbm5uYqNja3Sv11d0EfBoZ+CQz8Fh34KDv0UnMrqJ2OMfv3116DuV3U8sMTHx/sv6ZSUn59f6r6Wktxut9xud6m2uLi4yigvaLGxsQz2ctBHwaGfgkM/BYd+Cg79FJzK6Ke6desGtZzjN92mpqYG3Kvi8Xi0Z88epaamOlQVAACwieOBpX///lq3bp0OHjzob8vKylJERIT69u3rXGEAAMAajgeWcePGKSYmRkOGDNGaNWu0YMEC3XXXXRo3bly1eAeL2+3W1KlTAy5R4f+jj4JDPwWHfgoO/RQc+ik4NvSTy5hgniWqXNu2bdOECROUnZ2tmJgYjRw5Uo8++qiioqKcLg0AAFjAisACAABwMo5fEgIAACgPgQUAAFiPwFLC8uXLdf7556tmzZpq1aqVFixYENR6Ho9Hf//731WvXj3FxMRo2LBh2rNnT6llnnvuOfXt21eNGzdWbGysLr74Yi1dujRgWykpKXK5XAHT0aNHw7KP4WBDPxljNH36dJ1zzjmqVauWunbtqk2bNoVl/8KlMvvp008/1Y033qhzzz1XERERGjRoUJnbOtPHU7D9ZPt4qsw+kqTs7Gx17dpVtWrVUnJysh577LGAV6XbNJZycnLUp08fRUdHq3Hjxrr77rtVUFBQ7nrBHue8vDxdffXViomJUb169TRmzJgyX00f6nGpKjb00w033FDmuFm1atWp71CIb9Q/7Xz00UemRo0a5qabbjLvv/++ue+++4zL5TJZWVnlrtuvXz+TmJhoFi1aZJYuXWratm1rzj//fHPs2DH/MklJSWbMmDHmnXfeMWvWrDFjx441kszLL79calvJyclm2LBhZuPGjaWmoqKisO9zKGzpp8zMTBMVFWVmzZpl1q1bZ6666ioTExNjvv/++7Dvcygqu5/mzJljWrRoYa6//nqTnJxsBg4cWOa2zvTxFGw/2TyeKruPvv32W1OnTh1z1VVXmXXr1plZs2aZqKgoM2PGjFLbsmUsHThwwCQkJJg///nPZtWqVWb+/Pmmbt265pZbbil33WCOc0FBgWnbtq1p27atWbZsmXnrrbdMYmJiwNipyHGpCrb006hRo0zz5s0Dxs3BgwdPeZ8ILP+nb9++5pJLLinVdt1115lzzz33pOtlZ2cbSWb16tX+tpycHONyucyiRYv8bb/88kvAun369DFt27Yt1ZacnBzUgHKKDf105MgRExsba9LT0/1tPp/PJCcnm5tvvvmU96kyVHY/FRYW+v+5e/fuJw0sZ/J4CqafbB9Pld1HaWlpJjk52fh8Pn9benq6iYuLM0ePHvW32TKWpk2bZqKjo83+/fv9bc8995ypUaOG2b179wnXC/Y4L1y40LhcLpOTk+NvW716tZFkNm/e7G8L9bhUFVv6adSoUaZNmzZh2ScuCemPrz9v2LBB11xzTan2ESNGaNu2bdq5c+cJ1125cqXi4uLUp08ff1vr1q3VoUMHrVixwt/WoEGDgHU7duyovLy8iu9AFbGln7Kzs+X1ejV8+HB/W1RUlIYOHVpqW06pin6KiKj+/9O1pZ9sHk9V0UcrV67UkCFDSr1GYsSIETp48KA2btwYvp0Jk5UrV6p3796lPt0yfPhwFRUVac2aNSdcL9jjvHLlSrVv316tW7f2t/Xp00f16tXzL1eR41JVbOincKv+/68XBt9//72OHTsW8CmAc889V5ICPh1QUk5Ojlq3bh3w0cVzzz33pOtJ0scff+z/GyW98cYbcrvdqlOnjgYMGKCvv/462F2pVLb0U/HyZdXx008/6ciRI+XvTCVyqp9OhPF0cjaPp8ruo99++025ubkB209NTZXL5QrYvg1jKScnJ6DeuLg4JSQklNsfUvnHuaztu1yuUp+RqchxqSo29FOx7777TnXr1lVUVJQ6deqkd999N6R9cvzjhzbIz8+XFPgBxfj4eEnSgQMHTrpuWR9ejI+PP+l6CxcuVHZ2tpYsWVKq/YorrlCXLl10zjnn6IcfftCjjz6qyy67TP/973/VvHnzIPeoctjST/n5+XK73apZs2bAtowxys/PV61atcrbnUrjRD+dCOMpuDpsHU+V3UfFn0Q5frmoqCjVrl271PZtGUuhHvtgj3Mw26/IcakqNvST9McZ8s6dO6tNmzY6ePCgnn32WV111VXKysrSsGHDTmmfTtvAUvwBxfI48X/aX331lcaNG6cbb7xRQ4YMKTXvySef9P9zt27d1LdvX6Wmpuof//iH5s6dG/Zaqms/VTWb++lkGE/2qa59VNVjCaeH22+/vdTvK664QpdccokeeOABAkuxrKwsjR07ttzltm3b5k/FHo+n1LziFF3yGuDx4uPjlZubG9Cen59f5no//vij+vfvr4suukjPPfdcufUlJCTosssu02effVbusqGojv0UHx8vn8+no0ePlvqvgPz8fLlcLn+d4WRrP52qM3U8nUxVjyeb+qj4v5CP335BQYEOHz580u1X9lg6kfj4+IB6pfKPfbDH+WTbT0pK8i8jhXZcqooN/VSWiIgIXX311br77rt15MiRUzp7edrewzJmzBiZP56COumUmpqqFi1a6Kyzzgq47naia3klpaamavv27QHvLCjr+t6+ffvUr18/NWzYUO+8847OOuusMO1t6KpjPxUvv3379oBtFb83INxs7CcbVcd+qurxZFMfRUdHKykpKWD7xevZOObKukei+KxVef0hlX+cy9q+MUbbt2/3b6Mix6Wq2NBPYReWZ41OA3379jWXXXZZqba//vWvQT86uHbtWn/b9u3bAx4d/PXXX82FF15omjVrZvLy8oKua/fu3SY2NtaKxwmNsaOfih+7u/fee/1tBQUFJiUlxYrHUI2p/H4q6WSPNR/vTBtPJZX3WLOt46my+ygtLc00a9bMFBQU+NvuvfdeExcXV+pR5+M5NZamTZtm6tSpY/Lz8/1tL7zwQtCP65Z3nIsf1/3f//7nb1u7dm2ZjzWHclyqii39dLzCwkLTuXPnkB51JrD8n+KXAN18881mw4YN5oEHHjAul8u8/fbbpZarUaOGGT16dKm2fv36maSkJPP222+bZcuWmXbt2gW8nKlPnz4mMjLSvPrqqwEv0Cm2cOFCc/3115vXX3/dvP/+++bFF180LVq0MPHx8eaHH36o3A4Ikg39ZMwfLzZyu91mzpw5Zv369ebqq6+25kVfxlR+P+3du9dkZWWZrKwsc95555lOnTr5f//222/GGMaTMcH1kzF2j6fK7qNvv/3WREdHm6uvvtqsX7/ezJkzJ+DFcTaNpeIXonXv3t2sXr3avPTSSyYuLi4gOPXq1cu0aNGiVFswx7n4hWjt2rUzy5cvN4sWLTJJSUknfHFcecfFKTb0086dO0337t3NvHnzzLp160xWVpbp1auXcblc5p133jnlfSKwlLB06VLTrl07ExUVZf70pz+Z+fPnBywjyYwaNapU28GDB83o0aNNXFycqVOnjhk6dGhAgpV0wqnYxo0bTY8ePUyDBg1MZGSkadCggRk+fHipF/PYwOl+MsaYoqIiM23aNJOYmGjcbrfp0qWLyc7ODvu+VkRl9tOGDRtO2E87duwwxjCejAmun4yxfzxVZh8ZY8y///1v06VLF+N2u01iYqLJzMws9QZb28bSN998Yy6//HJTq1Yt07BhQzN58uSAs0Hdu3c3ycnJpdqCPc67du0yQ4cONXXq1DFxcXFm9OjRxuPxBCwXzHFxktP9tH//fnPFFVeYxMREExUVZerUqWN69OhhVq1aFdL+uIw57gInAACAZU7bm24BAMDpg8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOv9P6ASekDezofgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "og_df = pd.DataFrame.from_dict(top_results_model_weights, orient=\"index\")\n",
    "\n",
    "onnx_df = pd.DataFrame.from_dict(top_results_onnx, orient=\"index\")\n",
    "\n",
    "df = og_df-onnx_df\n",
    "\n",
    "\n",
    "df.x1.mean()\n",
    "\n",
    "df.x2.mean()\n",
    "\n",
    "df.y1.mean()\n",
    "\n",
    "df.y2.mean()\n",
    "\n",
    "%matplotlib inline\n",
    "df.confidence.plot.hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293bab57-259b-4613-b11a-e5c52e40a8ae",
   "metadata": {},
   "source": [
    "# debugging difference between results due to libjpeg difference\n",
    "\n",
    "below is a lot of messy scratch work to debug the differences between arrays loaded with PIL due to libjpeg versions. the conclusion is that libjpeg installed by conda differs from pip, but its inconsequential for model results, confidence isn't lower or higher on average depending on the libjpeg version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2dd25-be14-43ea-9e9a-46c113fc0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "ts = torch.load(\"test.arr\")\n",
    "\n",
    "diff = ts - im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aef737-2950-4262-ae4c-d891ce02992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diff > 0).sum() / (ts.shape[-1] * ts.shape[-2])\n",
    "\n",
    "(diff < 0).sum() / (ts.shape[-1] * ts.shape[-2])\n",
    "\n",
    "ts.shape[-1] * ts.shape[-2]\n",
    "diff = np.moveaxis(diff.numpy()[0], 0, -1)\n",
    "plt.figure()\n",
    "plt.imshow(diff)\n",
    "\n",
    "diff[diff>0] = 1\n",
    "\n",
    "diff[diff<0] = -1\n",
    "plt.figure()\n",
    "plt.imshow(diff)\n",
    "plt.figure()\n",
    "plt.title(\"pixel locations of absolute difference in input to model for Torchserve vs Truth\")\n",
    "\n",
    "plt.imshow( np.moveaxis(im[0].numpy(), 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c0ccf-6688-48de-956b-b07e6c3be68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.load(\"test-before-letterbox.arr.npy\")\n",
    "im = load_image(pth)\n",
    "im = np.asarray(im)\n",
    "diff = ts - im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2a8cc-f62a-4cf7-aa05-107c00473b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diff > 0).sum() / (ts.shape[0] * ts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd910e-2ffc-4937-8e50-d9ebdc95788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diff < 0).sum() / (ts.shape[-1] * ts.shape[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09563477-8bff-41e2-8f68-80e1fe0ab1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pth, 'rb') as f:\n",
    "    image_data = f.read()\n",
    "image_bytearray = bytearray(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73752ec-efd5-4304-8dae-563a32328acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_from_bytearray = load_image(io.BytesIO(image_bytearray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96a67d-a955-464b-b91e-9aa0aeea3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_from_pth = load_image(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fe1fa-afe2-4f5f-ab01-f9b48daec391",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.asarray(image_from_bytearray) == np.asarray(image_from_pth)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc2cb2-c7e3-41f1-99dd-c5033ac18502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.load(\"test-after-letterbox.arr.npy\")\n",
    "im = load_image(pth)\n",
    "im = np.asarray(im)\n",
    "im = letterbox(im, new_shape=img_size,\n",
    "            stride=64, auto=True)[0]\n",
    "diff = ts - im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac813a15-ac04-4088-89c9-730a308f6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diff > 0).sum() / (ts.shape[0] * ts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bad2a9-f4a2-418c-bfde-58485a773d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diff < 0).sum() / (ts.shape[0] * ts.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84228cf4-330b-41b6-8f6f-82c8027dc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63423022-709d-447e-94f6-3c3bc5e161f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9aae87-afe8-4b6e-a8c4-490707ca2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff[diff>0] = 1\n",
    "\n",
    "diff[diff<0] = -1\n",
    "\n",
    "plt.imshow(diff)\n",
    "plt.title(\"pixel locations of absolute difference in input to model for Torchserve vs Truth\")\n",
    "\n",
    "plt.imshow( np.moveaxis(im[0], 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205ffd5-83e5-49a2-8a4d-4847ceeb6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65066a58-4af1-402b-bbe1-bcd6cc50ea64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mdv5a]",
   "language": "python",
   "name": "conda-env-mdv5a-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
